# ðŸ§  ViT-Implementation â€” Vision Transformer from Scratch

This repository features a **from-scratch PyTorch implementation** of the **Vision Transformer (ViT)** architecture, inspired by [Dosovitskiy et al.](https://arxiv.org/abs/2010.11929). It includes all core components: patch embeddings, multi-head self-attention, transformer encoder blocks, and a custom training pipeline.

## ðŸš€ Getting Started
- **Train:** `python -m src.train`
- **Evaluate:** `python -m src.evaluate`
- **Generate Results CSV:** `python -m src.csv_generator`

## ðŸ“¦ Features
- Patch Embeddings
- GELU Activations
- Multi-Head Self-Attention
- Transformer Encoder Blocks with residuals & layer norm
- Modular and easy-to-read PyTorch code

## ðŸ“‹ Requirements
Install dependencies with:
```bash
pip install -r requirements.txt

---
```markdown
# ðŸ§  ViT-Implementation â€” Vision Transformer desde cero

Este repositorio contiene una implementaciÃ³n en **PyTorch desde cero** del **Vision Transformer (ViT)**, basada en el trabajo de [Dosovitskiy et al.](https://arxiv.org/abs/2010.11929). Incluye los componentes clave: embeddings de parches, atenciÃ³n multi-cabeza, bloques transformadores y un pipeline de entrenamiento personalizado.

## ðŸš€ Comenzar
- **Entrenar:** `python -m src.train`
- **Evaluar:** `python -m src.evaluate`
- **Generar CSV de resultados:** `python -m src.csv_generator`

## ðŸ“¦ Funcionalidades
- Embeddings de parches
- Activaciones GELU
- AtenciÃ³n multi-cabeza
- Bloques Transformer con residual y normalizaciÃ³n
- CÃ³digo modular y fÃ¡cil de entender

## ðŸ“‹ Requisitos
Instala las dependencias con:
```bash
pip install -r requirements.txt
