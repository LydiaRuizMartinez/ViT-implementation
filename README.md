# 🧠 ViT-Implementation — Your Friendly Vision Transformer!

Welcome to **ViT-Implementation**, a from-scratch PyTorch build of the **Vision Transformer (ViT)** architecture! Inspired by Dosovitskiy et al.’s [ViT paper](https://arxiv.org/abs/2010.11929), this repo walks you through how to classify images using transformers — without relying on any pretrained models.

---

## 🚀 Quick Start

### 🏋️‍♀️ 1. Train the Model
```bash
python -m src.train
```

### 🧠 2. Evaluate the Model
```bash
python -m src.evaluate
```

### 📊 3. Generate CSV with Results
```bash
python -m src.csv_generator
```

---

## 🧩 Features

- ✅ Patch Embeddings — split images into patches and process them like tokens.
- ✅ Multi-Head Self-Attention — multiple attention heads for rich feature extraction.
- ✅ Transformer Encoder Blocks — with residual connections and layer norm.
- ✅ GELU Activation — smoother than ReLU.
- ✅ Fully modular PyTorch code — clean, readable, and reusable.
- ✅ No pretrained shortcuts — everything built from scratch!

---

## 📦 Requirements

Install dependencies with:
```bash
pip install -r requirements.txt
```

---

# 🧠 ViT-Implementation — ¡Tu Transformer de Visión Amigable!

Bienvenid@ a **ViT-Implementation**, una implementación desde cero del modelo **Vision Transformer (ViT)** en PyTorch. Inspirado en el [artículo original](https://arxiv.org/abs/2010.11929) de Dosovitskiy et al., este repositorio te guía paso a paso para clasificar imágenes usando transformadores — sin modelos preentrenados.

---

## 🚀 Cómo Empezar

### 🏋️‍♀️ 1. Entrenar el Modelo
```bash
python -m src.train
```

### 🧠 2. Evaluar el Modelo
```bash
python -m src.evaluate
```

### 📊 3. Generar CSV con Resultados
```bash
python -m src.csv_generator
```

---

## 🧩 Características

- ✅ Patch Embeddings — divide imágenes en parches como tokens.
- ✅ Multi-Head Self-Attention — múltiples cabezas de atención para captar más contexto.
- ✅ Bloques de Codificador Transformer — con conexiones residuales y normalización.
- ✅ Activación GELU — más suave que ReLU.
- ✅ Código PyTorch modular — claro, legible y reutilizable.
- ✅ Todo construido desde cero — sin atajos preentrenados.

---

## 📦 Requisitos

Instala las dependencias con:
```bash
pip install -r requirements.txt
```

---

